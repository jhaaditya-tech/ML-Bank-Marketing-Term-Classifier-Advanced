{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Extracting dataset...\n",
      "Dataset loaded successfully.\n",
      "First few rows of the dataset:\n",
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download and Extract Dataset\n",
    "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip'\n",
    "dataset_path = 'bank-additional.zip'\n",
    "extracted_folder = 'bank-additional'\n",
    "\n",
    "# Download and Extract Dataset\n",
    "print(\"Downloading dataset...\")\n",
    "urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "print(\"Extracting dataset...\")\n",
    "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder)\n",
    "\n",
    "# Load the CSV file\n",
    "data_file_path = os.path.join(extracted_folder, 'bank-additional', 'bank-additional-full.csv')\n",
    "data = pd.read_csv(data_file_path, sep=';')\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "# Convert target column to binary\n",
    "data['y'] = data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle Class Imbalance Using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Apply PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "X_resampled_pca = pca.fit_transform(X_resampled)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  55.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  46.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  52.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  47.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  43.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  40.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  35.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  56.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  57.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  56.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  57.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.2s\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Hyperparameter Tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Define Stratified K-Fold with 5 splits\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=30,\n",
    "    cv=stratified_kfold,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "random_search_rf.fit(X_resampled_pca, y_resampled)\n",
    "best_rf = random_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning for logisitc regression\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['lbfgs', 'liblinear'],  # Common solvers for small/medium datasets\n",
    "    'penalty': ['l2'],  # Regularization type\n",
    "    'max_iter': [100, 200, 500]  # Number of iterations\n",
    "}\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform Randomized Search for Logistic Regression\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=lr,\n",
    "    param_distributions=param_grid_lr,\n",
    "    n_iter=20,  # Number of hyperparameter combinations to try\n",
    "    cv=stratified_kfold,  # Use Stratified K-Fold\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit Logistic Regression on resampled data\n",
    "random_search_lr.fit(X_resampled_pca, y_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_lr = random_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  41.8s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  42.0s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  42.6s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  42.9s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  43.1s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  43.8s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  43.9s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  44.6s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  44.7s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  44.7s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.6s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.2s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  41.4s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.5s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.7s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  42.8s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  43.6s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  44.4s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  44.8s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  44.0s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  34.5s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  36.8s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  37.0s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  36.1s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  37.6s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  37.0s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  35.7s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  37.7s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  38.1s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  37.5s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  33.9s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.6s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.2s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  35.5s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  37.7s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.2s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.6s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  37.1s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  41.7s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  44.5s\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time=  59.2s\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.1min\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.3min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.3min\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.4min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.0min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.2min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.0min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.2min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.2min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.4min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.3min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.3min\n"
     ]
    }
   ],
   "source": [
    "# # # Step 8: Hyperparameter Tuning for SVM\n",
    "# # param_grid_svm = {\n",
    "# #     'C': [0.1, 1, 10],\n",
    "# #     'kernel': ['linear', 'rbf', 'poly'],\n",
    "# #     'gamma': ['scale', 'auto']\n",
    "# # }\n",
    "\n",
    "# # # Define Stratified K-Fold with 5 splits\n",
    "# # stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # svm = SVC(probability=True, random_state=42)\n",
    "# # random_search_svm = RandomizedSearchCV(\n",
    "# #     estimator=svm,\n",
    "# #     param_distributions=param_grid_svm,\n",
    "# #     n_iter=20,\n",
    "# #     cv=stratified_kfold,\n",
    "# #     n_jobs=-1,\n",
    "# #     verbose=2,\n",
    "# #     random_state=42\n",
    "# # )\n",
    "# # random_search_svm.fit(X_resampled_pca, y_resampled)\n",
    "# # best_svm = random_search_svm.best_estimator_\n",
    "\n",
    "# # Step 1: Initialize the SVC model\n",
    "# \n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': np.logspace(-1, 1, 3),\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm = SVC(probability=False, random_state=42)\n",
    "random_search_svm = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_grid_svm,\n",
    "    n_iter=20,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "random_search_svm.fit(X_resampled, y_resampled)\n",
    "best_svm = random_search_svm.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;svm&#x27;, SVC(C=10.0, random_state=42)),\n",
       "                             (&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=1, max_iter=200,\n",
       "                                                 random_state=42))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;VotingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;svm&#x27;, SVC(C=10.0, random_state=42)),\n",
       "                             (&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=1, max_iter=200,\n",
       "                                                 random_state=42))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=200,\n",
       "                       random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=10.0, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1, max_iter=200, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     n_estimators=200,\n",
       "                                                     random_state=42)),\n",
       "                             ('svm', SVC(C=10.0, random_state=42)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=1, max_iter=200,\n",
       "                                                 random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 9: Ensemble Voting Classifier with Logistic Regression\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf),  # Random Forest\n",
    "    ('svm', best_svm),  # SVM\n",
    "    ('lr', best_lr)  # Logistic Regression\n",
    "], voting='soft')  # 'soft' voting uses predicted probabilities\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_clf.fit(X_resampled_pca, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Set Evaluation:\n",
      "Accuracy: 0.8930161042324188\n",
      "Precision: 0.5223214285714286\n",
      "Recall: 0.5883620689655172\n",
      "F1 Score: 0.5533783783783783\n",
      "Confusion Matrix:\n",
      " [[10216   749]\n",
      " [  573   819]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 10: Model Evaluation on Test Set\n",
    "# Random Forest Evaluation\n",
    "y_pred_rf = best_rf.predict(X_test_pca)\n",
    "y_pred_rf_proba = best_rf.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_rf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Set Evaluation:\n",
      "Accuracy: 0.9011896091284293\n",
      "Precision: 0.5540113708149084\n",
      "Recall: 0.6300287356321839\n",
      "F1 Score: 0.5895798319327731\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "# Apply PCA transformation to the test data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Predictions using Logistic Regression\n",
    "y_pred_lr = best_lr.predict(X_test_pca)\n",
    "\n",
    "# Evaluate Metrics\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "# Print Evaluation Results\n",
    "print(\"Logistic Regression Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"Precision:\", precision_lr)\n",
    "print(\"Recall:\", recall_lr)\n",
    "print(\"F1 Score:\", f1_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of PCA-transformed test data: (12357, 40)\n",
      "Number of features expected by SVM: 40\n",
      "SVM Test Set Evaluation:\n",
      "Accuracy: 0.9043457149793639\n",
      "Precision: 0.5830696202531646\n",
      "Recall: 0.5294540229885057\n",
      "F1 Score: 0.5549698795180723\n",
      "Confusion Matrix:\n",
      " [[10438   527]\n",
      " [  655   737]]\n"
     ]
    }
   ],
   "source": [
    "# PCA Transformation on Training Data\n",
    "X_train_pca = pca.fit_transform(X_resampled)  # Fit PCA on the training data\n",
    "best_svm.fit(X_train_pca, y_resampled)  # Train SVM on PCA-transformed training data\n",
    "\n",
    "# Apply PCA Transformation on Test Data\n",
    "X_test_pca = pca.transform(X_test)  # Use the same PCA object fitted on training data\n",
    "\n",
    "# Check feature dimensions before evaluation\n",
    "print(\"Shape of PCA-transformed test data:\", X_test_pca.shape)\n",
    "print(\"Number of features expected by SVM:\", best_svm.n_features_in_)\n",
    "assert X_test_pca.shape[1] == best_svm.n_features_in_, \"Feature dimension mismatch!\"\n",
    "\n",
    "# SVM Evaluation\n",
    "y_pred_svm = best_svm.predict(X_test_pca)\n",
    "\n",
    "# Evaluate SVM Performance\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1 Score:\", f1_svm)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validation Scores: [0.9377565  0.9334506  0.93696863 0.94205023 0.93579595]\n",
      "Random Forest Mean Cross-Validation Score: 0.9372043827519214\n",
      "SVM Cross-Validation Scores: [0.94352159 0.94439558 0.94224568 0.94889084 0.94586143]\n",
      "SVM Mean Cross-Validation Score: 0.9449830250836572\n",
      "Logistic Regression Cross-Validation Scores: [0.93062341 0.92778266 0.92905306 0.93237565 0.92563276]\n",
      "Logistic Regression Mean Cross-Validation Score: 0.9290935087772472\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Perform Cross-Validation for Random Forest\n",
    "cross_val_rf = cross_val_score(best_rf, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cross_val_rf)\n",
    "print(\"Random Forest Mean Cross-Validation Score:\", cross_val_rf.mean())\n",
    "\n",
    "# Perform Cross-Validation for SVM\n",
    "cross_val_svm = cross_val_score(best_svm, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"SVM Cross-Validation Scores:\", cross_val_svm)\n",
    "print(\"SVM Mean Cross-Validation Score:\", cross_val_svm.mean())\n",
    "\n",
    "# Step 8: Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_resampled_pca, y_resampled)\n",
    "\n",
    "# Perform Cross-Validation for Logistic Regression\n",
    "cross_val_lr = cross_val_score(log_reg, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cross_val_lr)\n",
    "print(\"Logistic Regression Mean Cross-Validation Score:\", cross_val_lr.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "This 'SVC' has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_available_if.py:29\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     check_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:822\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability:\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    823\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m     )\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when probability=False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Voting Classifier Evaluation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred_voting \u001b[38;5;241m=\u001b[39m \u001b[43mvoting_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_pca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m accuracy_voting \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_voting)\n\u001b[1;32m      5\u001b[0m precision_voting \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred_voting)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:440\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    438\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 440\u001b[0m     maj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'hard' voting\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:481\u001b[0m, in \u001b[0;36mVotingClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m    Weighted average probability for each class per sample.\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    479\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    480\u001b[0m avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(\n\u001b[0;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_probas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights_not_none\n\u001b[1;32m    482\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:456\u001b[0m, in \u001b[0;36mVotingClassifier._collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_collect_probas\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X) \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_])\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_available_if.py:40\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, owner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mowner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m         out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;66;03m# This makes it possible to use the decorated method as an unbound method,\u001b[39;00m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;66;03m# for instance when monkeypatching.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_available_if.py:31\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     29\u001b[0m     check_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_result:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: This 'SVC' has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# Voting Classifier Evaluation\n",
    "y_pred_voting = voting_clf.predict(X_test_pca)\n",
    "\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "precision_voting = precision_score(y_test, y_pred_voting)\n",
    "recall_voting = recall_score(y_test, y_pred_voting)\n",
    "f1_voting = f1_score(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Voting Classifier Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_voting)\n",
    "print(\"Precision:\", precision_voting)\n",
    "print(\"Recall:\", recall_voting)\n",
    "print(\"F1 Score:\", f1_voting)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, Precision: 0.2547709923664122, Recall: 0.959051724137931, F1 Score: 0.4025934861278649\n",
      "Threshold: 0.2, Precision: 0.349957971420566, Recall: 0.8972701149425287, F1 Score: 0.5035275146139891\n",
      "Threshold: 0.30000000000000004, Precision: 0.4265313791807591, Recall: 0.8153735632183908, F1 Score: 0.5600789538613373\n",
      "Threshold: 0.4, Precision: 0.47539417104634496, Recall: 0.7147988505747126, F1 Score: 0.5710186513629842\n",
      "Threshold: 0.5, Precision: 0.5194479297365119, Recall: 0.5948275862068966, F1 Score: 0.5545880776959142\n",
      "Threshold: 0.6000000000000001, Precision: 0.5860113421550095, Recall: 0.4454022988505747, F1 Score: 0.5061224489795918\n",
      "Threshold: 0.7000000000000001, Precision: 0.6368159203980099, Recall: 0.27586206896551724, F1 Score: 0.3849624060150376\n",
      "Threshold: 0.8, Precision: 0.7083333333333334, Recall: 0.1221264367816092, F1 Score: 0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Threshold Optimization for Random Forest\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "for threshold in thresholds:\n",
    "    y_pred_new_rf = (y_pred_rf_proba >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y_pred_new_rf)\n",
    "    recall = recall_score(y_test, y_pred_new_rf)\n",
    "    f1 = f1_score(y_test, y_pred_new_rf)\n",
    "    print(f\"Threshold: {threshold}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
