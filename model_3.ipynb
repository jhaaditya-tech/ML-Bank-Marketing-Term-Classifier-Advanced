{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Extracting dataset...\n",
      "Dataset loaded successfully.\n",
      "First few rows of the dataset:\n",
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download and Extract Dataset\n",
    "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip'\n",
    "dataset_path = 'bank-additional.zip'\n",
    "extracted_folder = 'bank-additional'\n",
    "\n",
    "# Download and Extract Dataset\n",
    "print(\"Downloading dataset...\")\n",
    "urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "print(\"Extracting dataset...\")\n",
    "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder)\n",
    "\n",
    "# Load the CSV file\n",
    "data_file_path = os.path.join(extracted_folder, 'bank-additional', 'bank-additional-full.csv')\n",
    "data = pd.read_csv(data_file_path, sep=';')\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "# Convert target column to binary\n",
    "data['y'] = data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle Class Imbalance Using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Apply PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "X_resampled_pca = pca.fit_transform(X_resampled)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  55.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  46.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  52.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  47.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  43.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  40.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  35.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  56.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  57.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  56.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  57.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.2s\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Hyperparameter Tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Define Stratified K-Fold with 5 splits\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=30,\n",
    "    cv=stratified_kfold,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "random_search_rf.fit(X_resampled_pca, y_resampled)\n",
    "best_rf = random_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning for logisitc regression\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['lbfgs', 'liblinear'],  # Common solvers for small/medium datasets\n",
    "    'penalty': ['l2'],  # Regularization type\n",
    "    'max_iter': [100, 200, 500]  # Number of iterations\n",
    "}\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform Randomized Search for Logistic Regression\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=lr,\n",
    "    param_distributions=param_grid_lr,\n",
    "    n_iter=20,  # Number of hyperparameter combinations to try\n",
    "    cv=stratified_kfold,  # Use Stratified K-Fold\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit Logistic Regression on resampled data\n",
    "random_search_lr.fit(X_resampled_pca, y_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_lr = random_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   7.3s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   7.5s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   7.5s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   7.6s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  11.5s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  11.5s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  11.6s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  11.8s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  11.8s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  38.8s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  39.6s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  39.1s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  39.4s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  40.6s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=   8.4s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=   7.8s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=   8.0s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=   8.1s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=   7.8s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=   5.0s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=   4.9s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=   5.3s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=   5.2s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=   4.8s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  42.9s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  43.4s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  44.8s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  44.4s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  46.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 50\u001b[0m\n\u001b[1;32m     38\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     39\u001b[0m     estimator\u001b[38;5;241m=\u001b[39msvm,\n\u001b[1;32m     40\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m           \u001b[38;5;66;03m# Optimize for accuracy\u001b[39;00m\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Step 5: Fit the random search on the training data\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Step 6: Retrieve the best parameters and model\u001b[39;00m\n\u001b[1;32m     53\u001b[0m best_params \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1959\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Step 8: Hyperparameter Tuning for SVM\n",
    "# param_grid_svm = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "\n",
    "# # Define Stratified K-Fold with 5 splits\n",
    "# stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# svm = SVC(probability=True, random_state=42)\n",
    "# random_search_svm = RandomizedSearchCV(\n",
    "#     estimator=svm,\n",
    "#     param_distributions=param_grid_svm,\n",
    "#     n_iter=20,\n",
    "#     cv=stratified_kfold,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2,\n",
    "#     random_state=42\n",
    "# )\n",
    "# random_search_svm.fit(X_resampled_pca, y_resampled)\n",
    "# best_svm = random_search_svm.best_estimator_\n",
    "\n",
    "# Step 1: Initialize the SVC model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Step 2: Define the parameter distribution\n",
    "param_dist = {\n",
    "    'C': np.logspace(-1, 1, 3),  # Logarithmic scale for C: [0.1, 1, 10]\n",
    "    'kernel': ['rbf', 'poly'],   # Focusing on non-linear kernels\n",
    "    'gamma': ['scale', 'auto']   # Common gamma values\n",
    "}\n",
    "\n",
    "# Step 3: Define the cross-validation strategy\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 4: Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,                   # Number of random parameter combinations to try\n",
    "    cv=stratified_kfold,         # Cross-validation strategy\n",
    "    n_jobs=-1,                   # Use all available CPU cores for parallel processing\n",
    "    verbose=2,                   # Display progress during search\n",
    "    random_state=42,             # Ensure reproducibility\n",
    "    scoring='accuracy'           # Optimize for accuracy\n",
    ")\n",
    "\n",
    "# Step 5: Fit the random search on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Retrieve the best parameters and model\n",
    "best_params = random_search.best_params_\n",
    "best_svm_model = random_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters from Randomized Search:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Ensemble Voting Classifier with Logistic Regression\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf),  # Random Forest\n",
    "    ('svm', best_svm),  # SVM\n",
    "    ('lr', best_lr)  # Logistic Regression\n",
    "], voting='soft')  # 'soft' voting uses predicted probabilities\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_clf.fit(X_resampled_pca, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Set Evaluation:\n",
      "Accuracy: 0.8930161042324188\n",
      "Precision: 0.5223214285714286\n",
      "Recall: 0.5883620689655172\n",
      "F1 Score: 0.5533783783783783\n",
      "Confusion Matrix:\n",
      " [[10216   749]\n",
      " [  573   819]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 10: Model Evaluation on Test Set\n",
    "# Random Forest Evaluation\n",
    "y_pred_rf = best_rf.predict(X_test_pca)\n",
    "y_pred_rf_proba = best_rf.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_rf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Set Evaluation:\n",
      "Accuracy: 0.9011896091284293\n",
      "Precision: 0.5540113708149084\n",
      "Recall: 0.6300287356321839\n",
      "F1 Score: 0.5895798319327731\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "# Apply PCA transformation to the test data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Predictions using Logistic Regression\n",
    "y_pred_lr = best_lr.predict(X_test_pca)\n",
    "\n",
    "# Evaluate Metrics\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "# Print Evaluation Results\n",
    "print(\"Logistic Regression Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"Precision:\", precision_lr)\n",
    "print(\"Recall:\", recall_lr)\n",
    "print(\"F1 Score:\", f1_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Evaluation\n",
    "y_pred_svm = best_svm.predict(X_test_pca)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1 Score:\", f1_svm)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Perform Cross-Validation for Random Forest\n",
    "cross_val_rf = cross_val_score(best_rf, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cross_val_rf)\n",
    "print(\"Random Forest Mean Cross-Validation Score:\", cross_val_rf.mean())\n",
    "\n",
    "# Perform Cross-Validation for SVM\n",
    "cross_val_svm = cross_val_score(best_svm, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"SVM Cross-Validation Scores:\", cross_val_svm)\n",
    "print(\"SVM Mean Cross-Validation Score:\", cross_val_svm.mean())\n",
    "\n",
    "# Step 8: Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_resampled_pca, y_resampled)\n",
    "\n",
    "# Perform Cross-Validation for Logistic Regression\n",
    "cross_val_lr = cross_val_score(log_reg, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cross_val_lr)\n",
    "print(\"Logistic Regression Mean Cross-Validation Score:\", cross_val_lr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier Evaluation\n",
    "y_pred_voting = voting_clf.predict(X_test_pca)\n",
    "\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "precision_voting = precision_score(y_test, y_pred_voting)\n",
    "recall_voting = recall_score(y_test, y_pred_voting)\n",
    "f1_voting = f1_score(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Voting Classifier Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_voting)\n",
    "print(\"Precision:\", precision_voting)\n",
    "print(\"Recall:\", recall_voting)\n",
    "print(\"F1 Score:\", f1_voting)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Threshold Optimization for Random Forest\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "for threshold in thresholds:\n",
    "    y_pred_new_rf = (y_pred_rf_proba >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y_pred_new_rf)\n",
    "    recall = recall_score(y_test, y_pred_new_rf)\n",
    "    f1 = f1_score(y_test, y_pred_new_rf)\n",
    "    print(f\"Threshold: {threshold}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
