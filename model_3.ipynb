{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Extracting dataset...\n",
      "Dataset loaded successfully.\n",
      "First few rows of the dataset:\n",
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download and Extract Dataset\n",
    "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip'\n",
    "dataset_path = 'bank-additional.zip'\n",
    "extracted_folder = 'bank-additional'\n",
    "\n",
    "# Download and Extract Dataset\n",
    "print(\"Downloading dataset...\")\n",
    "urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "print(\"Extracting dataset...\")\n",
    "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder)\n",
    "\n",
    "# Load the CSV file\n",
    "data_file_path = os.path.join(extracted_folder, 'bank-additional', 'bank-additional-full.csv')\n",
    "data = pd.read_csv(data_file_path, sep=';')\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "# Convert target column to binary\n",
    "data['y'] = data['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle Class Imbalance Using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Apply PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "X_resampled_pca = pca.fit_transform(X_resampled)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  55.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  46.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  51.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  52.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  46.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  47.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  27.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  43.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  21.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  29.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  40.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  35.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  56.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  57.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  56.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  57.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.8s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.2s\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Hyperparameter Tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Define Stratified K-Fold with 5 splits\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=30,\n",
    "    cv=stratified_kfold,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "random_search_rf.fit(X_resampled_pca, y_resampled)\n",
    "best_rf = random_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ........C=1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=200, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ......C=100, max_iter=200, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ...C=10, max_iter=500, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..C=100, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning for logisitc regression\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['lbfgs', 'liblinear'],  # Common solvers for small/medium datasets\n",
    "    'penalty': ['l2'],  # Regularization type\n",
    "    'max_iter': [100, 200, 500]  # Number of iterations\n",
    "}\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform Randomized Search for Logistic Regression\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=lr,\n",
    "    param_distributions=param_grid_lr,\n",
    "    n_iter=20,  # Number of hyperparameter combinations to try\n",
    "    cv=stratified_kfold,  # Use Stratified K-Fold\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit Logistic Regression on resampled data\n",
    "random_search_lr.fit(X_resampled_pca, y_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_lr = random_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  41.8s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  42.0s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  42.6s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  42.9s\n",
      "[CV] END ....................C=0.1, gamma=scale, kernel=poly; total time=  43.1s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  43.8s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  43.9s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  44.6s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  44.7s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=  44.7s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.6s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.2s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  41.4s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.5s\n",
      "[CV] END .....................C=0.1, gamma=auto, kernel=poly; total time=  40.7s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  42.8s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  43.6s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  44.4s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  44.8s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=  44.0s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  34.5s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  36.8s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  37.0s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  36.1s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  37.6s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  37.0s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  35.7s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  37.7s\n",
      "[CV] END .....................C=1.0, gamma=scale, kernel=rbf; total time=  38.1s\n",
      "[CV] END ....................C=1.0, gamma=scale, kernel=poly; total time=  37.5s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  33.9s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.6s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.2s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  35.5s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  37.7s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.2s\n",
      "[CV] END ......................C=1.0, gamma=auto, kernel=rbf; total time=  36.6s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  37.1s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  41.7s\n",
      "[CV] END .....................C=1.0, gamma=auto, kernel=poly; total time=  44.5s\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time=  59.2s\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.1min\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.3min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=scale, kernel=rbf; total time= 1.4min\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.3min\n",
      "[CV] END ...................C=10.0, gamma=scale, kernel=poly; total time= 1.4min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.0min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.4min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.2min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.0min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.2min\n",
      "[CV] END ....................C=10.0, gamma=auto, kernel=poly; total time= 1.2min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.4min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.3min\n",
      "[CV] END .....................C=10.0, gamma=auto, kernel=rbf; total time= 1.3min\n"
     ]
    }
   ],
   "source": [
    "# # # Step 8: Hyperparameter Tuning for SVM\n",
    "# # param_grid_svm = {\n",
    "# #     'C': [0.1, 1, 10],\n",
    "# #     'kernel': ['linear', 'rbf', 'poly'],\n",
    "# #     'gamma': ['scale', 'auto']\n",
    "# # }\n",
    "\n",
    "# # # Define Stratified K-Fold with 5 splits\n",
    "# # stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # svm = SVC(probability=True, random_state=42)\n",
    "# # random_search_svm = RandomizedSearchCV(\n",
    "# #     estimator=svm,\n",
    "# #     param_distributions=param_grid_svm,\n",
    "# #     n_iter=20,\n",
    "# #     cv=stratified_kfold,\n",
    "# #     n_jobs=-1,\n",
    "# #     verbose=2,\n",
    "# #     random_state=42\n",
    "# # )\n",
    "# # random_search_svm.fit(X_resampled_pca, y_resampled)\n",
    "# # best_svm = random_search_svm.best_estimator_\n",
    "\n",
    "# # Step 1: Initialize the SVC model\n",
    "# \n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': np.logspace(-1, 1, 3),\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm = SVC(probability=False, random_state=42)\n",
    "random_search_svm = RandomizedSearchCV(\n",
    "    estimator=svm,\n",
    "    param_distributions=param_grid_svm,\n",
    "    n_iter=20,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "random_search_svm.fit(X_resampled, y_resampled)\n",
    "best_svm = random_search_svm.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Ensemble Voting Classifier with Logistic Regression\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf),  # Random Forest\n",
    "    ('svm', best_svm),  # SVM\n",
    "    ('lr', best_lr)  # Logistic Regression\n",
    "], voting='soft')  # 'soft' voting uses predicted probabilities\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_clf.fit(X_resampled_pca, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Set Evaluation:\n",
      "Accuracy: 0.8930161042324188\n",
      "Precision: 0.5223214285714286\n",
      "Recall: 0.5883620689655172\n",
      "F1 Score: 0.5533783783783783\n",
      "Confusion Matrix:\n",
      " [[10216   749]\n",
      " [  573   819]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 10: Model Evaluation on Test Set\n",
    "# Random Forest Evaluation\n",
    "y_pred_rf = best_rf.predict(X_test_pca)\n",
    "y_pred_rf_proba = best_rf.predict_proba(X_test_pca)[:, 1]\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_rf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Set Evaluation:\n",
      "Accuracy: 0.9011896091284293\n",
      "Precision: 0.5540113708149084\n",
      "Recall: 0.6300287356321839\n",
      "F1 Score: 0.5895798319327731\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "# Apply PCA transformation to the test data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Predictions using Logistic Regression\n",
    "y_pred_lr = best_lr.predict(X_test_pca)\n",
    "\n",
    "# Evaluate Metrics\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "# Print Evaluation Results\n",
    "print(\"Logistic Regression Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"Precision:\", precision_lr)\n",
    "print(\"Recall:\", recall_lr)\n",
    "print(\"F1 Score:\", f1_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Feature dimension mismatch!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test)  \u001b[38;5;66;03m# Ensure the PCA object from training is used\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check feature dimensions\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X_test_pca\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m best_svm\u001b[38;5;241m.\u001b[39mn_features_in_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature dimension mismatch!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# SVM Evaluation\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_pred_svm \u001b[38;5;241m=\u001b[39m best_svm\u001b[38;5;241m.\u001b[39mpredict(X_test_pca)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Feature dimension mismatch!"
     ]
    }
   ],
   "source": [
    "# PCA Transformation on Training Data\n",
    "X_train_pca = pca.fit_transform(X_resampled)  # Fit PCA on the training data\n",
    "best_svm.fit(X_train_pca, y_resampled)  # Train SVM on PCA-transformed training data\n",
    "\n",
    "# Apply PCA Transformation on Test Data\n",
    "X_test_pca = pca.transform(X_test)  # Use the same PCA object fitted on training data\n",
    "\n",
    "# Check feature dimensions before evaluation\n",
    "print(\"Shape of PCA-transformed test data:\", X_test_pca.shape)\n",
    "print(\"Number of features expected by SVM:\", best_svm.n_features_in_)\n",
    "assert X_test_pca.shape[1] == best_svm.n_features_in_, \"Feature dimension mismatch!\"\n",
    "\n",
    "# SVM Evaluation\n",
    "y_pred_svm = best_svm.predict(X_test_pca)\n",
    "\n",
    "# Evaluate SVM Performance\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1 Score:\", f1_svm)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Perform Cross-Validation for Random Forest\n",
    "cross_val_rf = cross_val_score(best_rf, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cross_val_rf)\n",
    "print(\"Random Forest Mean Cross-Validation Score:\", cross_val_rf.mean())\n",
    "\n",
    "# Perform Cross-Validation for SVM\n",
    "cross_val_svm = cross_val_score(best_svm, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"SVM Cross-Validation Scores:\", cross_val_svm)\n",
    "print(\"SVM Mean Cross-Validation Score:\", cross_val_svm.mean())\n",
    "\n",
    "# Step 8: Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_resampled_pca, y_resampled)\n",
    "\n",
    "# Perform Cross-Validation for Logistic Regression\n",
    "cross_val_lr = cross_val_score(log_reg, X_resampled_pca, y_resampled, cv=skf)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cross_val_lr)\n",
    "print(\"Logistic Regression Mean Cross-Validation Score:\", cross_val_lr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier Evaluation\n",
    "y_pred_voting = voting_clf.predict(X_test_pca)\n",
    "\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "precision_voting = precision_score(y_test, y_pred_voting)\n",
    "recall_voting = recall_score(y_test, y_pred_voting)\n",
    "f1_voting = f1_score(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Voting Classifier Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_voting)\n",
    "print(\"Precision:\", precision_voting)\n",
    "print(\"Recall:\", recall_voting)\n",
    "print(\"F1 Score:\", f1_voting)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Threshold Optimization for Random Forest\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "for threshold in thresholds:\n",
    "    y_pred_new_rf = (y_pred_rf_proba >= threshold).astype(int)\n",
    "    precision = precision_score(y_test, y_pred_new_rf)\n",
    "    recall = recall_score(y_test, y_pred_new_rf)\n",
    "    f1 = f1_score(y_test, y_pred_new_rf)\n",
    "    print(f\"Threshold: {threshold}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
